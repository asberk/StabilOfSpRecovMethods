%% Numerical experiments: Exploring LASSO parameters
% 
% There is more than one kind of LASSO. Where b = A*x is [relatively]
% low-dimensional data generated by some measurement process A from some
% [relatively] high-dimensional data x, we see to recover x given knowledge
% of only A and y. 
%
% Basis Pursuit: 
%    (BP) min { OneNorm(x) : Ax = b } 
%  (BPDN) min { OneNorm(x) : TwoNorm(Ax-b) ≤ sigma }
% (LASSO) min { TwoNorm(Ax-b) : OneNorm(x) ≤ tau }
%   (UCL) min { TwoNorm(Ax-b) + lambda*OneNorm(x) }
%
% Friedlander and van den Berg give a relatively thorough description of
% how the parameters sigma, tau and lambda relate to each other [SIAM,
% 2008]. However, while the predominant belief is that (BPDN) and (LASSO)
% are stable with respect to variation in the parameters tau and sigma, we
% aim to show through numerical experiments situations in which this is not
% the case - i.e., paradigms in which reconstruction error bounds are
% grossly sub-optimal. 

%% Set-up
% erase workspace
close all; clear all; clc;

% Add path to SPGL1 library (for my system)
if ~isempty( strfind(pwd, 'aberk') )
    addpath ~/Documents/MATLAB/spgl1-1.9/
end
% Set random number generator parameters for reproduceability 
rand('twister', 0); randn('state', 0); % set types of rngs that MATLAB uses

%%
% Set matrix and sparsity sizes (note that these should be varied)
m = 50; n = 128; k = 14; % # of rows, columns and nnz elemns, resp.
[A,Rtmp] = qr(randn(n,m),0); % random encoding matrix with orthogonal rows
A = A'; % A is mxnsz_sigdel

% noise level 
epsilon = 0.1;

% Define vectors x0 and b
p = randperm(n); p = p(1:k); % Location of k nonzeros (nnzs) in x
x0 = zeros(n,1); x0(p) = randn(k,1); % The k-sparse solution
b0 = A*x0; % The right-hand side corresponding to x0
z = rand(m,1);

%% Basis Pursuit De-Noise (BPDN) 
%
% We run basis pursuit for varying values of tau, chosen based on the
% one-norm of x0. 

% set up sigma; want sigma to range from smaller than the norm of x to e.g.
% twice the SD of the noise z. 

opts = spgSetParms('verbosity', 0);
% noiseless
sigma_lo = 0; 
sigma_hi = norm(b0); % from Pareto curve, we know that TwoNorm(Ax-b) lies in the interval (sigma_lo, sigma_hi)
nIter = 101;
dsigma = linspace(sigma_hi, 0, nIter); % most tolerant of error to least tolerant of error

X_bpdn_nonoise = zeros(n, nIter);
for j = 1:nIter
  X_bpdn_nonoise(:,j) = spg_bpdn(A,b0, max(0, dsigma(j)), opts);
end

%% Analyze results - BPDN

R_bpdn_nonoise = bsxfun(@minus, X_bpdn_nonoise, x0);
R_norm_bpdn_nonoise = vecNorm(R_bpdn_nonoise);

for j = 1:nIter
    plot(x0, 'r*'); hold on; 
    stem(X_bpdn_nonoise(:,j), 'b '); 
    stem(abs(R_bpdn_nonoise(:,j)), 'g '); hold off;
    title({'iteration ', j});
    pause;
    
end

%% LASSO (LS) 
N = 200; % highest dimension that we will test

tau_lo = 0; % how low can you go 
tau_hi = norm(x0) + 2*sqrt(epsilon); % the ideal choice for this parameter is denoted tau_BP in Friedlander and vdBerg 2008 
dtau = linspace(tau_lo, tau_hi, nIter);

lasso_nonoise = zeros(N, nIter);

for nn = 1:N
    X_lasso_nonoise = zeros(nn, nIter);
    % R_lasso_nonoise = zeros(nn, nIter);
    % R_norm_lasso_nonoise = zeros(1, nIter);
    for j = 1:nIter
        X_lasso_nonoise(:,j) = spg_lasso(A,b0, dtau(j), opts);
        % R_lasso_nonoise(:,j) = X_lasso_nonoise(:,j) - x0;
        % R_norm_lasso_nonoise(j) = norm(R_lasso_nonoise(:,j));
        lasso_nonoise(nn, j) = norm(X_lasso_nonoise(:,j) - x0); % R_norm_lasso_nonoise(j);
    end
end
    
for j = 1:nIter
    plot (x0, 'r*'); hold on;
    stem(X_lasso_nonoise(:,j), 'b '); 
    hold off;
    title({'iteration ', j});
    pause;
end
    

plot(lasso_nonoise, 'b.-');
    
    
    
    
    
    